import logging
import ollama
import os
import subprocess
from diffusers import StableDiffusionPipeline
import torch
from PIL import Image

# Ativar o logging
logging.basicConfig(level=logging.DEBUG)

class AIModel:
    def __init__(self, model_name="gemma:2b"):
        self.model_name = model_name
        logging.info(f"Model {model_name} is ready to use with Ollama.")
        self.sd_pipe = None
        self.base_url = os.getenv("OLLAMA_HOST", "http://localhost:11434")

    def generate_response(self, prompt):
        try:
            logging.debug(f"Sending prompt to the model: {prompt}")

            # Gerar a resposta com Ollama
            response = ollama.chat(model=self.model_name, messages=[
                {'role': 'user', 'content': prompt}
            ])

            # Extraindo a resposta do modelo
            message = response.get('message', {}).get('content', '')

            logging.debug(f"Response generated by the model: {message}")

            # Verifica se a resposta está vazia
            if not message:
                logging.warning("The response generated by the model was empty.")
                return "Sorry, I couldn't generate a response."

            # Adiciona a informação do modelo no final da resposta
            return f"{message}\n\nAI Model: {self.model_name}"

        except Exception as e:
            logging.error(f"Unexpected error while generating response: {str(e)}")
            return f"An unexpected error occurred: {str(e)}"

    def generate_image(self, prompt, output_path="generated_image.png"):
        try:
            if self.sd_pipe is None:
                logging.info("Loading Stable Diffusion pipeline...")
                self.sd_pipe = StableDiffusionPipeline.from_pretrained(
                    "runwayml/stable-diffusion-v1-5",
                    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32
                )
                if torch.cuda.is_available():
                    self.sd_pipe = self.sd_pipe.to("cuda")

            logging.debug(f"Generating image with prompt: {prompt}")
            image = self.sd_pipe(prompt).images[0]
            image.save(output_path)
            logging.info(f"Image saved to {output_path}")
            return output_path
        except Exception as e:
            logging.error(f"Failed to generate image: {str(e)}")
            return f"Error generating image: {str(e)}"
